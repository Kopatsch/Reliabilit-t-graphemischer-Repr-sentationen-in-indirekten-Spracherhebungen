{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "words = [\"ameise\", \"begräbnis\", \"deichsel\", \"elster\", \"fledermaus\", \"gurke\", \"hagebutte\", \"hebamme\", \"kartoffel\", \"maulwurf\", \"pflaume\", \"stecknadel\", \"ziege\", \"zimmerfliege\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def na_detector(df_spalte):\n",
    "    df_spalte_neu = []\n",
    "    for number in df_spalte:\n",
    "        if number > 999:\n",
    "            number = number % 999\n",
    "        df_spalte_neu.append(number)\n",
    "    return df_spalte_neu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in words:\n",
    "    path = f'/home/kopatsch/Masterarbeit/MA/masterarbeit/data/lexem/{word}'\n",
    "    entries = os.listdir(path)\n",
    "    \n",
    "    df_list = []\n",
    "\n",
    "    for entry in entries:\n",
    "        df = pd.read_csv(f\"{path}/{entry}\", sep = \"\\t\")\n",
    "        df_list.append(df)\n",
    "    \n",
    "\n",
    "    result = pd.concat(df_list)\n",
    "    result = result.drop(columns = [\"Unnamed: 0\"])\n",
    "    \n",
    "    result = result.groupby(\"Koordinaten\").agg(Fragebogen_maurer = (\"Fragebogen_maurer\", set),\n",
    "                                                Fragebogen_DWA = (\"Fragebogen_DWA\", set),\n",
    "                                                Ort = (\"Ort\", set),\n",
    "                                                item_maurer = (\"item_maurer\", set),\n",
    "                                                item_DWA = (\"item_DWA\", set),\n",
    "                                                Levenshtein_item = (\"Levenshtein_item\", \"sum\"),\n",
    "                                                phontype_maurer = (\"phontype_maurer\", set),\n",
    "                                                phontype_DWA = (\"phontype_DWA\", set),\n",
    "                                                Levenshtein_phontype = (\"Levenshtein_phontype\", \"sum\"),\n",
    "                                                lextype_maurer = (\"lextype_maurer\", set),\n",
    "                                                lextype_DWA = (\"lextype_DWA\", set),\n",
    "                                                Levenshtein_lextype = (\"Levenshtein_lextype\", \"sum\"))\n",
    "    \n",
    "\n",
    "    item = na_detector(result[\"Levenshtein_item\"])\n",
    "    result[\"Levenshtein_item\"] = item\n",
    "    phontype = na_detector(result[\"Levenshtein_phontype\"])\n",
    "    result[\"Levenshtein_phontype\"] = phontype\n",
    "    lextype = na_detector(result[\"Levenshtein_lextype\"])\n",
    "    result[\"Levenshtein_lextype\"] = lextype\n",
    "\n",
    "    result_clean = pd.DataFrame()\n",
    "    for column in result:\n",
    "        liste = []\n",
    "        for j in result[column]:\n",
    "            j = str(j)\n",
    "            j = j.replace(\"{\", \"\")\n",
    "            j = j.replace(\"}\", \"\")\n",
    "            j = j.replace(\"\\'\", \"\")\n",
    "            j = j.replace(\"\\\"\", \"\")\n",
    "            j = j.replace(\"nan\", \"na\")\n",
    "            j = j.replace(\"na, \", \"\")\n",
    "            j = j.replace(\", na\", \"\")\n",
    "            j = j.strip()\n",
    "            liste.append(j)\n",
    "        result_clean[column] = liste\n",
    "\n",
    "    result_clean.insert(loc=3, column='Koordinaten', value=result.index)\n",
    "    long = []\n",
    "    lat = []\n",
    "    for coords in result_clean[\"Koordinaten\"]:\n",
    "        coords = str(coords)\n",
    "        coord = coords.split(\", \")\n",
    "        long.append(float(coord[0]))\n",
    "        lat.append(float(coord[1]))\n",
    "    \n",
    "    result_clean.insert(loc=4, column='Longitude', value=long)\n",
    "    result_clean.insert(loc=5, column='Latitude', value=lat)\n",
    "\n",
    "    result_clean.to_csv(f\"/home/kopatsch/Masterarbeit/MA/masterarbeit/data/lexem_gesamt/all_levenshtein_lexem_added_{word}.csv\", sep = \"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste der Untersuchungsworte\n",
    "# Vereinfacht die Automatisierungen verschidener Funktionen im weiteren Scriptverlauf\n",
    "words = [\"ameise\", \"begräbnis\", \"deichsel\", \"elster\", \"fledermaus\", \"gurke\", \"hagebutte\", \"hebamme\", \"kartoffel\", \"maulwurf\", \"pflaume\", \"stecknadel\", \"ziege\", \"zimmerfliege\"]\n",
    "\n",
    "levenshtein_item = []\n",
    "levenshtein_phon= []\n",
    "levenshtein_lex = []\n",
    "for word in words:\n",
    "    df = pd.read_csv(f\"/home/kopatsch/Masterarbeit/MA/masterarbeit/data/levenshtein_single_files/{word}.csv\", sep= \"\\t\")\n",
    "    df1 = df.drop(df[df[\"Levenshtein Item Min\"] == 999].index)\n",
    "    liste1 = list(df1[\"Levenshtein Item Min\"])\n",
    "    for x in liste1:\n",
    "        levenshtein_item.append(x)\n",
    "        levenshtein_phon.append(x)\n",
    "        levenshtein_lex.append(x)\n",
    "    df2 = df.drop(df[df[\"Levenshtein Phontype Min\"] == 999].index)\n",
    "    liste2 = list(df2[\"Levenshtein Phontype Min\"])\n",
    "    for x in liste2:\n",
    "        levenshtein_phon.append(x)\n",
    "        levenshtein_lex.append(x)\n",
    "    df3 = df.drop(df[df[\"Levenshtein Lextype Min\"] == 999].index)\n",
    "    liste3 = list(df3[\"Levenshtein Lextype Min\"])\n",
    "    for x in liste3:\n",
    "        levenshtein_lex.append(x)\n",
    "\n",
    "\n",
    "mittel_item = np.mean(levenshtein_item)\n",
    "stvar_item = np.std(levenshtein_item)\n",
    "mittel_phon = np.mean(levenshtein_phon)\n",
    "stvar_phon = np.std(levenshtein_phon)\n",
    "mittel_lex = np.mean(levenshtein_lex)\n",
    "stvar_lex = np.std(levenshtein_lex)\n",
    "\n",
    "for word in words:\n",
    "    df = pd.read_csv(f\"/home/kopatsch/Masterarbeit/MA/masterarbeit/data/lexem_gesamt/all_levenshtein_lexem_added_{word}.csv\", sep= \"\\t\")\n",
    "    df.insert(loc = 10, column = \"z_score_item\", value = ((df[\"Levenshtein_item\"]-mittel_item)/stvar_item))\n",
    "    df.insert(loc = 14, column = \"z_score_phontype\", value = ((df[\"Levenshtein_phontype\"]-mittel_phon)/stvar_phon))\n",
    "    df.insert(loc = 18, column = \"z_score_lextype\", value = ((df[\"Levenshtein_lextype\"]-mittel_lex)/stvar_lex))\n",
    "    df = df.drop(columns = [\"Unnamed: 0\"])\n",
    "    df.to_csv(f\"/home/kopatsch/Masterarbeit/MA/masterarbeit/data/lexem_gesamt/all_levenshtein_lexem_added_{word}.csv\", sep= \"\\t\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
