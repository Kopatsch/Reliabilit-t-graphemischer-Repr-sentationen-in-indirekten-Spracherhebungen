{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jupyter Notebook zur Berechnung der Levenshtein Distanz zwischen Maurer-Graphem und DWA-Graphem für jeden vorkommenden Abfrageort\n",
    "\n",
    "Um die Levenshtein Distanzen pro Ort berechnen zu können, muss der Datensatz (Datensatz = jede csv Datei im \"csv\"-Ordner) zunächst nach Maurer- und DWA-Bögen getrennt werden.\n",
    "Danach werden die Maurer- und DWA-Bögen so zusammengefasst, dass jeder Ort nur einmal im Datensatz vorkommt.\n",
    "Die daraus resultierenden zwei Datensätze können dann anhand der Koordinaten zusammengeführt werden.\n",
    "Das Ergebis ist ein Gesamtdatensatz, in dem für jeden Abfrageort alle Maurer- und DWA-Angaben gebündelt gegenübergestellt sind.\n",
    "Dadurch kann pro Ort die Levenshtein Distanz (Minimale Anzahl an Substitutionen, Ergänzungen und Substraktionen, um einen String in einen zweiten zu überführen) zwischen Maurer- und DWA-Graphemen berechnet werden. Für Orte, an denen mehr als ein Maurer- bzw. DWA-Graphem vorliegt, wird die Distanz zwischen allen möglichen vorkommenden Kombinationen berechnet und der daraus resultierende Minimalwert in den Datensatz übernommen.\n",
    "Orte, an denen kein Graphem vorliegt, bekommen die Kennziffer `999` zugeschrieben. Dies gilt auch für Orte, an denen die Grapheme nicht verglichen werden können, da kein Vergleichsdatensatz vorliegt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from Levenshtein import distance\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataframe(file):\n",
    "    \"\"\"\n",
    "    Creates a pandas dataframe and drops \"korrektur\" and \"org\" columns\n",
    "    \n",
    "    Parameters:\n",
    "    file(csv): must provide source to the csv file that is to be made into a dataframe\n",
    "    \n",
    "    Returns:\n",
    "    df_sorted: pd.DataFrame\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(file, sep = \"\\t\", index_col = False)\n",
    "    df_sorted = df.drop(columns = [\"korrektur\", \"org\"])\n",
    "    return df_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leven(val1, val2):\n",
    "    \"\"\"\n",
    "    computes Levenshtein distance for two given values\n",
    "\n",
    "    Parameters:\n",
    "    val1(str or list): list must be comprised of str elements. Function checks if parameter is str or list. \n",
    "    If parameter is list, function will compute Levenshtein distance for each str within list.\n",
    "    val2(str or list): list must be comprised of str elements. \n",
    "    Function checks if parameter is str or list. If parameter is list, function will compute Levenshtein distance for each str within list.\n",
    "\n",
    "    Returns:\n",
    "    minimum (int): minimal Levenshein distance computed for two given values\n",
    "    \"\"\"\n",
    "    val1 = str(val1)\n",
    "    val2 = str(val2)\n",
    "    \n",
    "    if \", \" in val1:\n",
    "        wert1 = val1.split(\", \")\n",
    "    else:\n",
    "        wert1 = val1.strip()\n",
    "\n",
    "    if \", \" in val2:\n",
    "        wert2 = val2.split(\", \")\n",
    "    else:\n",
    "        wert2 = val2.strip()\n",
    "\n",
    "    dist = []\n",
    "\n",
    "    if type(wert1) == str and type(wert2) == str:\n",
    "        if wert1 == \"na\" or wert1 == \"nan\" or wert2 == \"na\" or wert2 == \"nan\":\n",
    "            dist_item = 999\n",
    "        else:  \n",
    "            dist_item = distance(wert1, wert2)\n",
    "        dist.append(dist_item)\n",
    "\n",
    "    elif type(wert1) == str and type(wert2) == list:\n",
    "        for a in wert2:\n",
    "            a = a.strip()\n",
    "            if wert1 == \"na\" or wert1 == \"nan\" or a == \"na\" or a == \"nan\":\n",
    "                dist_item = 999\n",
    "            else:  \n",
    "                dist_item = distance(wert1, a)\n",
    "            dist.append(dist_item)\n",
    "\n",
    "    elif type(wert2) == str and type(wert1) == list:\n",
    "        for c in wert1:\n",
    "            c = c.strip()\n",
    "            if c == \"na\" or c == \"nan\" or wert2 == \"na\" or wert2 == \"nan\":\n",
    "                dist_item = 999\n",
    "            else:\n",
    "                dist_item = distance(wert2, c)\n",
    "            dist.append(dist_item)\n",
    "    \n",
    "    elif type(wert1) == list and type(wert2) == list:\n",
    "        for l in wert1:\n",
    "            l = l.strip()\n",
    "            for b in wert2:\n",
    "                b = b.strip()\n",
    "                if l == \"na\" or l == \"nan\" or b == \"na\" or b == \"nan\":\n",
    "                    dist_item = 999\n",
    "                else:\n",
    "                    dist_item = distance(l, b)\n",
    "                dist.append(dist_item)\n",
    "    \n",
    "    minimum = min(dist)\n",
    "\n",
    "    return minimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stringer(object):\n",
    "    \"\"\"\n",
    "    changes datatype into str\n",
    "\n",
    "    Parameters:\n",
    "    object(instance of an \"Ort\" object)\n",
    "\n",
    "    Returns:\n",
    "    object\n",
    "    \"\"\"\n",
    "    object.fragebogen = str(object.fragebogen)\n",
    "    object.fragebogen2 = str(object.fragebogen2)\n",
    "    object.ort = str(object.ort)\n",
    "    object.item = str(object.item)\n",
    "    object.item2 = str(object.item2)\n",
    "    object.phontype = str(object.phontype)\n",
    "    object.phontype2 = str(object.phontype2)\n",
    "    object.lextype = str(object.lextype)\n",
    "    object.lextype2 = str(object.lextype2)\n",
    "    return object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_unique(befragung):\n",
    "    \"\"\"\n",
    "    reverses questionnaire splitting and sums up data per location\n",
    "\n",
    "    Parameters:\n",
    "    befragung (list): takes in list of objects\n",
    "\n",
    "    Returns:\n",
    "    unique(list)\n",
    "    \"\"\"\n",
    "    # In unique kommt jeder Ort und jeder Fragebogen nur 1 Mal vor\n",
    "    unique = []\n",
    "\n",
    "    # Belegsplittung rückgängig machen\n",
    "    for object in befragung:\n",
    "        if object.beleg == 1:\n",
    "            unique.append(object)\n",
    "\n",
    "    for object in befragung:\n",
    "        if object.beleg > 1:\n",
    "            for i in unique:\n",
    "                if object.fragebogen == i.fragebogen:\n",
    "                    i.add(\"na\", object.ort, object.item, object.phontype, object.lextype)\n",
    "\n",
    "    # Datensatz pro Ort zusammenfassen\n",
    "    x = 0\n",
    "    for i in unique:\n",
    "        for j in unique[x::]:\n",
    "            if i != j:\n",
    "                if i.long == j.long and i.lat == j.lat:\n",
    "                    i.add(j.fragebogen, j.ort, j.item, j.phontype, j.lextype)\n",
    "                    unique.remove(j)\n",
    "        x += 1\n",
    "    \n",
    "    return unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ort:\n",
    "    def __init__(self, fragebogen, ort, long, lat, item, phontype, lextype, beleg, erhebung):\n",
    "        \"\"\"\n",
    "        Init function to create instance of \"Ort\" object.\n",
    "        Takes in the information for each questionnaire given in the dataset.\n",
    "        \"\"\"\n",
    "        self.fragebogen = fragebogen\n",
    "        # fragebogen2, item2 etc. enthalten später die Grapheme aus dem DWA Bogen\n",
    "        # fragebogen, item etc. enthalten die Grapheme aus der Maurerbefragung\n",
    "        self.fragebogen2 = \"na\"\n",
    "        self.ort = ort\n",
    "        self.long = long\n",
    "        self.lat = lat\n",
    "        self.item = item\n",
    "        self.item2 = \"na\"\n",
    "        self.phontype = phontype\n",
    "        self.phontype2 = \"na\"\n",
    "        self.lextype = lextype\n",
    "        self.lextype2 = \"na\"\n",
    "        self.beleg = beleg\n",
    "        self.erhebung = erhebung\n",
    "\n",
    "    def add(self, fragebogen, ort, item, phontype, lextype):\n",
    "        \"\"\"\n",
    "        function to add the name of the questionnaire, items, phontypes and lextypes to \n",
    "        an existing object instance in case there is more than one questionnaire per place\n",
    "\n",
    "        Parameters:\n",
    "        fragebogen(string)\n",
    "        ort(string)\n",
    "        item(sting)\n",
    "        phontype(string)\n",
    "        lextype(string)\n",
    "    \n",
    "        Returns:\n",
    "        self: changed instance of self\n",
    "        \"\"\"\n",
    "        self.fragebogen += f\", {fragebogen}\"\n",
    "        self.ort += f\", {ort}\"\n",
    "        self.item += f\", {item}\"\n",
    "        self.phontype += f\", {phontype}\"\n",
    "        self.lextype += f\", {lextype}\"\n",
    "\n",
    "    def info(self):\n",
    "        \"\"\"\n",
    "        provides information about an instance\n",
    "\n",
    "        Parameters:\n",
    "        self(instance of an object)\n",
    "\n",
    "        Returns:\n",
    "        print statement\n",
    "        \"\"\"\n",
    "        print(self.fragebogen, self.fragebogen2, self.ort, self.item, self.item2, self.phontype, self.phontype2, self.lextype, self.lextype2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/kopatsch/Masterarbeit/MA/masterarbeit/data/csv/\"\n",
    "entries = os.listdir(path)\n",
    "\n",
    "for entry in entries:\n",
    "    df = make_dataframe(f\"{path}{entry}\")\n",
    "\n",
    "    # Dataframe transponieren, um die nachfolgende Erstellung der Objectinstanzen mittels Verwendung von Indizes zu erleichtern\n",
    "    df2 = df.T\n",
    "\n",
    "    # Liste, die alle Objektinstanzen beinhaltet\n",
    "    gesamt_liste = []\n",
    "    for i in df2:\n",
    "        # kreieren der Objektinstanzen\n",
    "        ort_object = Ort(df2[i][1], df2[i][2], df2[i][4], df2[i][5], df2[i][6], df2[i][7], df2[i][8], df2[i][9], df2[i][10])\n",
    "        gesamt_liste.append(ort_object)\n",
    "\n",
    "    # Datensatz in einen Maurer- und einen DWA-Datensatz aufteilen\n",
    "    maurer = []\n",
    "    dwa = []\n",
    "    for object in gesamt_liste:\n",
    "        if object.erhebung == \"maurer\":\n",
    "            maurer.append(object)\n",
    "        elif object.erhebung == \"DWA\":\n",
    "            dwa.append(object)\n",
    "\n",
    "    # In maurer_unique kommt jeder Ort und jeder Fragebogen nur 1 Mal vor\n",
    "    maurer_unique = list_unique(maurer)\n",
    "\n",
    "    # In dwa_unique kommt jeder Ort und jeder Fragebogen nur 1 Mal vor\n",
    "    dwa_unique = list_unique(dwa)\n",
    "\n",
    "    # DWA- und Maurer-Datensätze mittels der Koordinaten zusammenführen\n",
    "    final_list = []\n",
    "    for i in maurer_unique:\n",
    "        switch = True\n",
    "        for j in dwa_unique:\n",
    "            # da es möglich sein kann, dass mehr als 1 DWA Bogen zu einem Maurer Bogen gehört,\n",
    "            # kann mit dem Switch überprüft werden, ob schon DWA Information im Object enthalten ist\n",
    "            if i.lat == j.lat and i.long == j.long and switch == True:\n",
    "                i.item2 = j.item\n",
    "                i.phontype2 = j.phontype\n",
    "                i.lextype2 = j.lextype\n",
    "                i.fragebogen2 = j.fragebogen\n",
    "                switch = False\n",
    "            elif i.lat == j.lat and i.long == j.long and switch == False:\n",
    "                i.item2 += \", \" + j.item\n",
    "                i.phontype2 += \", \" + j.phontype\n",
    "                i.lextype2 += \", \" + j.lextype\n",
    "                i.fragebogen2 += \", \" + j.fragebogen\n",
    "        final_list.append(i)\n",
    "\n",
    "    for i in dwa_unique:\n",
    "        # switch überprüft, ob DWA Daten bereits in der finalen Liste enthalten sind\n",
    "        switch = True\n",
    "        for j in final_list:\n",
    "            if i.lat == j.lat and i.long == j.long:\n",
    "                switch = False\n",
    "        if switch == True:\n",
    "            final_list.append(i)\n",
    "\n",
    "    # Levenshtein Distanzen pro Ort berechnen\n",
    "    lev_item_min= []\n",
    "    lev_phontype_min = []\n",
    "    lev_lextype_min = []\n",
    "\n",
    "    for element in final_list:\n",
    "        result1 = leven(element.item, element.item2)\n",
    "        lev_item_min.append(result1)\n",
    "\n",
    "        result2 = leven(element.phontype, element.phontype2)\n",
    "        lev_phontype_min.append(result2)\n",
    "\n",
    "        result3 = leven(element.lextype, element.lextype2)\n",
    "        lev_lextype_min.append(result3)\n",
    "\n",
    "    # Daten nach Kategorien sortiert in Listen abspeichern\n",
    "    # Listen zu einem pandas DataFrame zusammenführen\n",
    "    df3 = pd.DataFrame()\n",
    "\n",
    "    fragebogen_maurer = []\n",
    "    fragebogen_dwa = []\n",
    "    ort = []\n",
    "    long = []\n",
    "    lat = []\n",
    "    item_maurer = []\n",
    "    item_dwa = []\n",
    "    phontype_maurer = []\n",
    "    phontype_dwa = []\n",
    "    lextype_maurer = []\n",
    "    lextype_dwa = []\n",
    "\n",
    "    for i in final_list:\n",
    "        i.fragebogen = i.fragebogen.replace(\", na\", \"\")\n",
    "        i.fragebogen2 = i.fragebogen2.replace(\", na\", \"\")\n",
    "        if i.erhebung == \"maurer\":\n",
    "            stringer(i)\n",
    "            fragebogen_maurer.append(i.fragebogen)\n",
    "            fragebogen_dwa.append(i.fragebogen2)\n",
    "            ort.append(i.ort)\n",
    "            long.append(i.long)\n",
    "            lat.append(i.lat)\n",
    "            item_maurer.append(i.item)\n",
    "            item_dwa.append(i.item2)\n",
    "            phontype_maurer.append(i.phontype)\n",
    "            phontype_dwa.append(i.phontype2)\n",
    "            lextype_maurer.append(i.lextype)\n",
    "            lextype_dwa.append(i.lextype2)\n",
    "        elif i.erhebung == \"DWA\":\n",
    "            stringer(i)\n",
    "            fragebogen_maurer.append(i.fragebogen2)\n",
    "            fragebogen_dwa.append(i.fragebogen)\n",
    "            ort.append(i.ort)\n",
    "            long.append(i.long)\n",
    "            lat.append(i.lat)\n",
    "            item_maurer.append(i.item2)\n",
    "            item_dwa.append(i.item)\n",
    "            phontype_maurer.append(i.phontype2)\n",
    "            phontype_dwa.append(i.phontype)\n",
    "            lextype_maurer.append(i.lextype2)\n",
    "            lextype_dwa.append(i.lextype)\n",
    "\n",
    "    df3[\"Fragebogen-Nr. Maurer\"] = fragebogen_maurer\n",
    "    df3[\"Fragebogen-Nr. DWA\"] = fragebogen_dwa\n",
    "    df3[\"Ort\"] = ort\n",
    "    df3[\"Longitude\"] = long\n",
    "    df3[\"Latitude\"] = lat\n",
    "    df3[\"Item Maurer\"] = item_maurer\n",
    "    df3[\"Item DWA\"] = item_dwa\n",
    "    df3[\"Levenshtein Item Min\"] = lev_item_min\n",
    "    df3[\"Phontype Maurer\"] = phontype_maurer\n",
    "    df3[\"Phontype DWA\"] = phontype_dwa\n",
    "    df3[\"Levenshtein Phontype Min\"] = lev_phontype_min\n",
    "    df3[\"Lextype Maurer\"] = lextype_maurer\n",
    "    df3[\"Lextype DWA\"] = lextype_dwa\n",
    "    df3[\"Levenshtein Lextype Min\"] = lev_lextype_min\n",
    "\n",
    "    filename = entry.split(\"Maurer_\")\n",
    "    filename = filename[1].lower()\n",
    "    # speichern\n",
    "    df3.to_csv(f\"/home/kopatsch/Masterarbeit/MA/masterarbeit/data/levenshtein_single_files/{filename}\", sep = \"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste der Untersuchungsworte\n",
    "# Vereinfacht die Automatisierungen verschidener Funktionen im weiteren Scriptverlauf\n",
    "words = [\"ameise\", \"begräbnis\", \"deichsel\", \"elster\", \"fledermaus\", \"gurke\", \"hagebutte\", \"hebamme\", \"kartoffel\", \"maulwurf\", \"pflaume\", \"stecknadel\", \"ziege\", \"zimmerfliege\"]\n",
    "\n",
    "levenshtein_item = []\n",
    "levenshtein_phon= []\n",
    "levenshtein_lex = []\n",
    "for word in words:\n",
    "    df = pd.read_csv(f\"/home/kopatsch/Masterarbeit/MA/masterarbeit/data/levenshtein_single_files/{word}.csv\", sep= \"\\t\")\n",
    "    df1 = df.drop(df[df[\"Levenshtein Item Min\"] == 999].index)\n",
    "    liste1 = list(df1[\"Levenshtein Item Min\"])\n",
    "    for x in liste1:\n",
    "        levenshtein_item.append(x)\n",
    "        levenshtein_phon.append(x)\n",
    "        levenshtein_lex.append(x)\n",
    "    df2 = df.drop(df[df[\"Levenshtein Phontype Min\"] == 999].index)\n",
    "    liste2 = list(df2[\"Levenshtein Phontype Min\"])\n",
    "    for x in liste2:\n",
    "        levenshtein_phon.append(x)\n",
    "        levenshtein_lex.append(x)\n",
    "    df3 = df.drop(df[df[\"Levenshtein Lextype Min\"] == 999].index)\n",
    "    liste3 = list(df3[\"Levenshtein Lextype Min\"])\n",
    "    for x in liste3:\n",
    "        levenshtein_lex.append(x)\n",
    "\n",
    "\n",
    "mittel_item = np.mean(levenshtein_item)\n",
    "stvar_item = np.std(levenshtein_item)\n",
    "mittel_phon = np.mean(levenshtein_phon)\n",
    "stvar_phon = np.std(levenshtein_phon)\n",
    "mittel_lex = np.mean(levenshtein_lex)\n",
    "stvar_lex = np.std(levenshtein_lex)\n",
    "\n",
    "\n",
    "for word in words:\n",
    "    df = pd.read_csv(f\"/home/kopatsch/Masterarbeit/MA/masterarbeit/data/levenshtein_single_files/{word}.csv\", sep= \"\\t\")\n",
    "    df.insert(loc = 9, column = \"z_score_item\", value = ((df[\"Levenshtein Item Min\"]-mittel_item)/stvar_item))\n",
    "    df.insert(loc = 13, column = \"z_score_phontype\", value = ((df[\"Levenshtein Phontype Min\"]-mittel_phon)/stvar_phon))\n",
    "    df.insert(loc = 17, column = \"z_score_lextype\", value = ((df[\"Levenshtein Lextype Min\"]-mittel_lex)/stvar_lex))\n",
    "    df = df.drop(columns = [\"Unnamed: 0\"])\n",
    "    df.to_csv(f\"/home/kopatsch/Masterarbeit/MA/masterarbeit/data/levenshtein_single_files/{word}.csv\", sep= \"\\t\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
