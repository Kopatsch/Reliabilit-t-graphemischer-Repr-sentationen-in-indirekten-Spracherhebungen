{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from Levenshtein import distance\n",
    "\n",
    "words = [\"ameise\", \"begr√§bnis\", \"deichsel\", \"elster\", \"fledermaus\", \"gurke\", \"hagebutte\", \"hebamme\", \"kartoffel\", \"maulwurf\", \"pflaume\", \"stecknadel\", \"ziege\", \"zimmerfliege\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leven(val1, val2, ziel):\n",
    "    \"\"\"\n",
    "    computes Levenshtein distance for two given values\n",
    "\n",
    "    Parameters:\n",
    "    val1(str or list): list must be comprised of str elements. Function checks if parameter is str or list. \n",
    "    If parameter is list, function will compute Levenshtein distance for each str within list.\n",
    "    val2(str or list): list must be comprised of str elements. \n",
    "    Function checks if parameter is str or list. If parameter is list, function will compute Levenshtein distance for each str within list.\n",
    "\n",
    "    Returns:\n",
    "    minimum (int): minimal Levenshein distance computed for two given values\n",
    "    \"\"\"\n",
    "    val1 = str(val1)\n",
    "    val2 = str(val2)\n",
    "    \n",
    "    if \", \" in val1:\n",
    "        wert1 = val1.split(\", \")\n",
    "    else:\n",
    "        wert1 = val1.strip()\n",
    "\n",
    "    if \", \" in val2:\n",
    "        wert2 = val2.split(\", \")\n",
    "    else:\n",
    "        wert2 = val2.strip()\n",
    "\n",
    "    dist = []\n",
    "\n",
    "    if type(wert1) == str and type(wert2) == str:\n",
    "        if wert1 == \"na\" or wert1 == \"999\" or wert1 == \"k.a.\" or wert1 == \"nan\" or wert2 == \"na\" or wert2 == \"999\" or wert2 == \"k.a.\" or wert2 == \"nan\":\n",
    "            dist_item = 999\n",
    "        else:  \n",
    "            dist_item = distance(wert1, wert2)\n",
    "        dist.append(dist_item)\n",
    "\n",
    "    elif type(wert1) == str and type(wert2) == list:\n",
    "        for a in wert2:\n",
    "            a = a.strip()\n",
    "            if wert1 == \"na\" or wert1 == \"999\" or wert1 == \"k.a.\" or wert1 == \"nan\" or a == \"na\" or a == \"999\" or a == \"k.a.\" or a == \"nan\":\n",
    "                dist_item = 999\n",
    "            else:  \n",
    "                dist_item = distance(wert1, a)\n",
    "            dist.append(dist_item)\n",
    "\n",
    "    elif type(wert2) == str and type(wert1) == list:\n",
    "        for c in wert1:\n",
    "            c = c.strip()\n",
    "            if c == \"na\" or c == \"999\" or c == \"k.a.\" or c == \"nan\" or wert2 == \"na\" or wert2 == \"999\" or wert2 == \"k.a.\" or wert2 == \"nan\":\n",
    "                dist_item = 999\n",
    "            else:\n",
    "                dist_item = distance(wert2, c)\n",
    "            dist.append(dist_item)\n",
    "    \n",
    "    elif type(wert1) == list and type(wert2) == list:\n",
    "        for l in wert1:\n",
    "            l = l.strip()\n",
    "            for b in wert2:\n",
    "                b = b.strip()\n",
    "                if l == \"na\" or l == \"999\" or l == \"k.a.\" or l == \"nan\" or b == \"na\" or b == \"999\" or b == \"k.a.\" or b == \"nan\":\n",
    "                    dist_item = 999\n",
    "                else:\n",
    "                    dist_item = distance(l, b)\n",
    "                dist.append(dist_item)\n",
    "    \n",
    "    minimum = min(dist)\n",
    "    ziel.append(minimum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstellung der Lexem files\n",
    "for word in words:\n",
    "    word_upper = word[0].upper() + word[1::]\n",
    "    df = pd.read_csv(f\"/home/kopatsch/Masterarbeit/MA/masterarbeit/data/csv/DWA_Maurer_{word_upper}.csv\", sep = \"\\t\")\n",
    "    df = df.fillna(\"na\")\n",
    "    df = df.replace(\"nan\", \"na\")\n",
    "\n",
    "    lexem = set(df[\"lextype\"])\n",
    "    lexem = list(lexem)\n",
    "    lexem.remove(\"na\")\n",
    "\n",
    "    for lex in lexem:\n",
    "        df1 = df.drop(df[df[\"lextype\"] != lex].index)\n",
    "        df1[\"coord\"] = df1[\"LONG\"].astype(str) + \", \" + df1[\"LAT\"].astype(str)\n",
    "\n",
    "        df1 = df1.drop(columns = [\"korrektur\", \"org\", \"belegnr.\", \"LONG\", \"LAT\", \"GID\", \"lfd\"])\n",
    "        df1 = df1.reset_index(drop=True)\n",
    "        \n",
    "        columns_liste = []\n",
    "        for i in df1:\n",
    "            columns_liste.append(i)\n",
    "\n",
    "        df1 = df1.rename({columns_liste[0]: \"Fragebogen\",\n",
    "                        columns_liste[1]: \"Ort\",\n",
    "                        columns_liste[2]: \"item\",\n",
    "                        columns_liste[3]: \"phontype\",\n",
    "                        columns_liste[4]: \"lextype\",\n",
    "                        columns_liste[5]: \"erhebung\",\n",
    "                        columns_liste[6]: \"coord\"}, axis = \"columns\")\n",
    "\n",
    "        maurer = df1.drop(df1[df1[\"erhebung\"] != \"maurer\"].index)\n",
    "        dwa = df1.drop(df1[df1[\"erhebung\"] != \"DWA\"].index)\n",
    "\n",
    "        switch = False\n",
    "        # weil dwa an zweiter Stelle steht beim Merge, muss diese Ausnahmeregelung eingebaut werden\n",
    "        if len(dwa) == 0:\n",
    "            dwa_unique = pd.DataFrame({\"Fragebogen_DWA\": [\"na\"],\n",
    "                                \"Ort_DWA\": [\"na\"],\n",
    "                                \"item_DWA\": [\"na\"],\n",
    "                                \"phontype_DWA\": [\"na\"],\n",
    "                                \"lextype_DWA\": [\"na\"],\n",
    "                                \"erhebung_DWA\": [\"na\"],\n",
    "                                \"coord\": [maurer[\"coord\"][0]]})\n",
    "            switch = True\n",
    "\n",
    "        maurer_unique = maurer.groupby(\"coord\").agg(Fragebogen_maurer = (\"Fragebogen\", set),\n",
    "                                                  Ort_maurer = (\"Ort\", set),\n",
    "                                                  item_maurer = (\"item\", set),\n",
    "                                                  phontype_maurer = (\"phontype\", set),\n",
    "                                                  lextype_maurer = (\"lextype\", set),\n",
    "                                                  erhebung_maurer = (\"erhebung\", set))\n",
    "\n",
    "        if switch == False:\n",
    "            dwa_unique = dwa.groupby(\"coord\").agg(Fragebogen_DWA = (\"Fragebogen\", set),\n",
    "                                                Ort_DWA = (\"Ort\", set),\n",
    "                                                item_DWA = (\"item\", set),\n",
    "                                                phontype_DWA = (\"phontype\", set),\n",
    "                                                lextype_DWA = (\"lextype\", set),\n",
    "                                                erhebung_DWA = (\"erhebung\", set))\n",
    "\n",
    "\n",
    "        result = pd.merge(maurer_unique, dwa_unique, how=\"outer\", on=[\"coord\"])\n",
    "        if switch == True:\n",
    "            # Koordinaten werden im Index abgespeichert\n",
    "            result.index = maurer_unique.index\n",
    "        result = result.astype(str)\n",
    "        result[\"Ort\"] = result[\"Ort_maurer\"] + \", \" + result[\"Ort_DWA\"]\n",
    "        \n",
    "        result_clean = pd.DataFrame()\n",
    "        for column in result:\n",
    "            liste = []\n",
    "            for j in result[column]:\n",
    "                j = str(j)\n",
    "                j = j.replace(\"{\", \"\")\n",
    "                j = j.replace(\"}\", \"\")\n",
    "                j = j.replace(\"\\'\", \"\")\n",
    "                j = j.replace(\"\\\"\", \"\")\n",
    "                j = j.replace(\"nan\", \"na\")\n",
    "                j = j.replace(\"na, \", \"\")\n",
    "                j = j.replace(\", na\", \"\")\n",
    "                j = j.strip()\n",
    "                liste.append(j)\n",
    "            result_clean[column] = liste\n",
    "\n",
    "        result_clean = result_clean.fillna(\"na\")\n",
    "        result_clean = result_clean.drop(columns = [\"Ort_maurer\", \"Ort_DWA\", \"erhebung_maurer\", \"erhebung_DWA\"])\n",
    "        result_clean = result_clean[[\"Fragebogen_maurer\", \"Fragebogen_DWA\", \"Ort\", \"item_maurer\", \"item_DWA\", \"phontype_maurer\", \"phontype_DWA\", \"lextype_maurer\", \"lextype_DWA\"]]\n",
    "\n",
    "        item = []\n",
    "        phontype = []\n",
    "        lextype = []\n",
    "\n",
    "        for i in range(len(result_clean)):\n",
    "            leven(result_clean[\"item_maurer\"][i], result_clean[\"item_DWA\"][i], item)\n",
    "            leven(result_clean[\"phontype_maurer\"][i], result_clean[\"phontype_DWA\"][i], phontype)\n",
    "            leven(result_clean[\"lextype_maurer\"][i], result_clean[\"lextype_DWA\"][i], lextype)\n",
    "\n",
    "        result_clean.insert(loc=5, column='Levenshtein_item', value=item)\n",
    "        result_clean.insert(loc=8, column='Levenshtein_phontype', value=phontype)\n",
    "        result_clean.insert(loc=11, column='Levenshtein_lextype', value=lextype)\n",
    "        result_clean.insert(loc=3, column='Koordinaten', value=result.index)\n",
    "\n",
    "        \n",
    "        result_clean.to_csv(f\"/home/kopatsch/Masterarbeit/MA/masterarbeit/data/lexem/{word}/DWA_Maurer_lexem_{lex}.csv\", sep = \"\\t\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
